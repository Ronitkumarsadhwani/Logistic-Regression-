{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Logistic Regression assignment\n"
      ],
      "metadata": {
        "id": "7-n2fjkOf1G2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#theory questions\n"
      ],
      "metadata": {
        "id": "dIiBr54QgC6X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q1. What is Logistic Regression, and how does it differ from Linear Regression?\n",
        " - Logistic Regression is a classification algorithm that predicts probabilities using the sigmoid function. Logistic Regression is used for classification, while Linear Regression is used for predicting continuous values. Logistic outputs probabilities between 0 and 1, while Linear outputs any real number. Logistic uses log-loss, while Linear uses mean squared error. Logistic coefficients explain log-odds, while Linear coefficients give direct change in the output.\n",
        "\n",
        "Q2. Role of Sigmoid function in Logistic Regression\n",
        " - The sigmoid function maps any linear value to a range between 0 and 1, which can be interpreted as probability. It is smooth and differentiable, making optimization possible. It connects the linear predictor to log-odds and allows thresholding, such as 0.5, to assign class labels.\n",
        "\n",
        "Q3. What is Regularization in Logistic Regression and why is it needed?\n",
        " - Regularization is the technique of adding a penalty to the size of model coefficients to prevent overfitting. L2 regularization (Ridge) shrinks weights, while L1 regularization (Lasso) forces sparsity and performs feature selection. Regularization is needed to improve generalization, handle multicollinearity, and stabilize the model.\n",
        "\n",
        "Q4. What are some common evaluation metrics for classification models, and\n",
        "why are they important?\n",
        " - Accuracy measures overall correctness. Precision measures how many predicted positives are correct. Recall measures how many actual positives are found. The F1-score balances precision and recall. ROC-AUC and PR-AUC evaluate performance across thresholds. These metrics are important because they capture different aspects of performance, especially for imbalanced data."
      ],
      "metadata": {
        "id": "vfLQwXo4gGmD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Practical Questions"
      ],
      "metadata": {
        "id": "NmwSdl4rhYpT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Question 5\n",
        "\"\"\"Write a Python program that loads a CSV file into a Pandas DataFrame,\n",
        "splits into train/test sets, trains a Logistic Regression model, and prints its accuracy.\n",
        "(Use Dataset from sklearn package) \"\"\"\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "model = LogisticRegression(max_iter=5000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dxzr-jedhX3T",
        "outputId": "c8e85187-94af-40b4-a51c-fb51e78a7dea"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.956140350877193\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Question 6\n",
        "\"\"\"Write a Python program to train a Logistic Regression model using L2\n",
        "regularization (Ridge) and print the model coefficients and accuracy.\n",
        "(Use Dataset from sklearn package) \"\"\"\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "model = LogisticRegression(penalty='l2', solver='lbfgs', max_iter=5000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "print(\"Coefficients:\", model.coef_)\n",
        "print(\"Accuracy:\", model.score(X_test, y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5LfhMX1Zh_TT",
        "outputId": "9bb0e42a-6295-431d-a7a0-3b608ca7c1d7"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coefficients: [[ 1.0274368   0.22145051 -0.36213488  0.0254667  -0.15623532 -0.23771256\n",
            "  -0.53255786 -0.28369224 -0.22668189 -0.03649446 -0.09710208  1.3705667\n",
            "  -0.18140942 -0.08719575 -0.02245523  0.04736092 -0.04294784 -0.03240188\n",
            "  -0.03473732  0.01160522  0.11165329 -0.50887722 -0.01555395 -0.016857\n",
            "  -0.30773117 -0.77270908 -1.42859535 -0.51092923 -0.74689363 -0.10094404]]\n",
            "Accuracy: 0.956140350877193\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Question 7\n",
        "\"\"\"Write a Python program to train a Logistic Regression model for multiclass\n",
        "classification using multi_class='ovr' and print the classification report.\n",
        "(Use Dataset from sklearn package)\"\"\"\n",
        "\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression(multi_class='ovr', max_iter=5000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YkxCK3ovilk1",
        "outputId": "06ada043-1289-4edf-c572-ac03dbfb3d5f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        10\n",
            "           1       1.00      0.89      0.94         9\n",
            "           2       0.92      1.00      0.96        11\n",
            "\n",
            "    accuracy                           0.97        30\n",
            "   macro avg       0.97      0.96      0.97        30\n",
            "weighted avg       0.97      0.97      0.97        30\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Question 8\n",
        "\"\"\"Write a Python program to apply GridSearchCV to tune C and penalty\n",
        "hyperparameters for Logistic Regression and print the best parameters and validation\n",
        "accuracy.\n",
        "(Use Dataset from sklearn package)\n",
        "\"\"\"\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = {\n",
        "    'C': [0.01, 0.1, 1, 10],\n",
        "    'penalty': ['l1', 'l2'],\n",
        "    'solver': ['liblinear']\n",
        "}\n",
        "\n",
        "grid = GridSearchCV(LogisticRegression(max_iter=5000), param_grid, cv=5)\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best parameters:\", grid.best_params_)\n",
        "print(\"Best validation accuracy:\", grid.best_score_)\n"
      ],
      "metadata": {
        "id": "_1MrSuCWilhW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b43851d-16f3-413d-9d31-83f5ddc6a96b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters: {'C': 10, 'penalty': 'l1', 'solver': 'liblinear'}\n",
            "Best validation accuracy: 0.9583333333333334\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Question 9\n",
        "\"\"\"Write a Python program to standardize the features before training Logistic\n",
        "Regression and compare the model's accuracy with and without scaling.\n",
        "(Use Dataset from sklearn package)\n",
        "\"\"\"\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "model = LogisticRegression(max_iter=5000)\n",
        "model.fit(X_train, y_train)\n",
        "print(\"Accuracy without scaling:\", model.score(X_test, y_test))\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "model_scaled = LogisticRegression(max_iter=5000)\n",
        "model_scaled.fit(X_train_scaled, y_train)\n",
        "print(\"Accuracy with scaling:\", model_scaled.score(X_test_scaled, y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3OopS6jIkxik",
        "outputId": "135aed06-f539-4dee-a304-6d1e557a4097"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy without scaling: 1.0\n",
            "Accuracy with scaling: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Question 10\n",
        "\n",
        "Imagine you are working at an e-commerce company that wants to\n",
        "predict which customers will respond to a marketing campaign. Given an imbalanced dataset (only 5% of customers respond), describe the approach you’d take to build a Logistic Regression model — including data handling, feature scaling, balancing classes, hyperparameter tuning, and evaluating the model for this real-world business use case.\n",
        "\n",
        "\n",
        "Answer:\n",
        "To build a Logistic Regression model for this case, I would follow these steps:\n",
        "\n",
        " - Data handling\n",
        "\n",
        "Clean missing values and encode categorical features.\n",
        "\n",
        "Remove duplicates and irrelevant columns.\n",
        "\n",
        "- Feature scaling\n",
        "\n",
        "Standardize numerical features so all are on the same scale, which is important for regularization.\n",
        "\n",
        " - Balancing classes\n",
        "\n",
        "Since only 5% respond, accuracy alone is misleading.\n",
        "\n",
        "Use methods like oversampling (SMOTE), undersampling, or class weights (class_weight='balanced' in LogisticRegression).\n",
        "\n",
        " - Hyperparameter tuning\n",
        "\n",
        "Use GridSearchCV to tune regularization strength (C), penalty type (L1 or L2), and solver.\n",
        "\n",
        " - Evaluation\n",
        "\n",
        "Focus on metrics like precision, recall, F1-score, and ROC-AUC instead of accuracy.\n",
        "\n",
        "Plot Precision-Recall curve since positives are rare.\n",
        "\n",
        "Adjust probability threshold depending on business need (e.g., maximize recall to target most responders).\n",
        "\n",
        " - Conclusion:\n",
        "By scaling features, balancing the dataset, carefully tuning hyperparameters, and using the right evaluation metrics, Logistic Regression can provide a reliable model for predicting customer response in an imbalanced e-commerce dataset.\n"
      ],
      "metadata": {
        "id": "N2qHD1UMlkPK"
      }
    }
  ]
}